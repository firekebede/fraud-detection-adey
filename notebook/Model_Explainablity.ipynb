{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "975b4ddf",
      "metadata": {
        "id": "975b4ddf"
      },
      "source": [
        "# Task 3 - Model Explainability with SHAP\n",
        "\n",
        "Using TreeExplainer for Random Forest model. Force plot is excluded to avoid crashes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "bf92249a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf92249a",
        "outputId": "50d9a8fe-47fa-4d9b-dfda-5f1501af7125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.48.0)\n",
            "Collecting imblearn\n",
            "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.16.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from shap) (4.14.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (from imblearn) (0.13.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn->imblearn) (0.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
            "Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
            "Installing collected packages: imblearn\n",
            "Successfully installed imblearn-0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install shap imblearn scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AXz9Jq9QxMx",
        "outputId": "900176d1-9ee6-4257-ee5f-d710b445e375"
      },
      "id": "7AXz9Jq9QxMx",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "26e81630",
      "metadata": {
        "id": "26e81630"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5df871b9",
      "metadata": {
        "id": "5df871b9"
      },
      "source": [
        "## Load and Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "2e577919",
      "metadata": {
        "id": "2e577919"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "fraud_data = pd.read_csv('/content/drive/MyDrive/week 8/Data/Fraud_Data.csv')\n",
        "fraud_data.drop_duplicates(inplace=True)\n",
        "fraud_data.dropna(inplace=True)\n",
        "fraud_data['signup_time'] = pd.to_datetime(fraud_data['signup_time'])\n",
        "fraud_data['purchase_time'] = pd.to_datetime(fraud_data['purchase_time'])\n",
        "fraud_data['time_since_signup'] = (fraud_data['purchase_time'] - fraud_data['signup_time']).dt.total_seconds()\n",
        "fraud_data['hour_of_day'] = fraud_data['purchase_time'].dt.hour\n",
        "fraud_data['day_of_week'] = fraud_data['purchase_time'].dt.dayofweek\n",
        "fraud_data.drop(['signup_time', 'purchase_time'], axis=1, inplace=True)\n",
        "fraud_data = pd.get_dummies(fraud_data, columns=['source', 'browser', 'sex'], drop_first=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb4dcb20",
      "metadata": {
        "id": "bb4dcb20"
      },
      "source": [
        "## Train-Test Split and Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "86dfeed9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86dfeed9",
        "outputId": "a2f408a0-d848-4c5c-a28e-a4bf354ef39a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96     27393\n",
            "           1       0.63      0.55      0.58      2830\n",
            "\n",
            "    accuracy                           0.93     30223\n",
            "   macro avg       0.79      0.76      0.77     30223\n",
            "weighted avg       0.92      0.93      0.92     30223\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Feature/Target split\n",
        "X = fraud_data.drop(['class', 'device_id'], axis=1)\n",
        "y = fraud_data['class']\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "# Handle imbalance\n",
        "sm = SMOTE(random_state=42)\n",
        "X_res, y_res = sm.fit_resample(X_train, y_train)\n",
        "# Scale\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_res)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "# Reconstruct DataFrames for SHAP\n",
        "X_train_df = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
        "X_test_df = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
        "# Train model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train_df, y_res)\n",
        "print(classification_report(y_test, model.predict(X_test_df)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8fc637e",
      "metadata": {
        "id": "b8fc637e"
      },
      "source": [
        "## SHAP Global Explanation (Summary Plot Only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de61116f",
      "metadata": {
        "id": "de61116f"
      },
      "outputs": [],
      "source": [
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X_test_df)\n",
        "shap.summary_plot(shap_values[1], X_test_df.iloc[:200])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c384783",
      "metadata": {
        "id": "3c384783"
      },
      "source": [
        "## Notes\n",
        "- SHAP summary plot shows the most influential features globally.\n",
        "- Force plot is skipped to avoid compatibility and performance issues in local environments."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p_Ieeu7dRRuB"
      },
      "id": "p_Ieeu7dRRuB",
      "execution_count": 8,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}